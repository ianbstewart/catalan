{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: audience effect\n",
    "In which we determine whether intended audience (using @-reply as \"audience\") affects Catalan usage in control data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id             user  \\\n",
      "0  850626678380535808     CampsCliment   \n",
      "1  850628981040848896         Dom70Bcn   \n",
      "2  850631111747276800  Estrellas_Siete   \n",
      "3  850632361649860608    pasionxespana   \n",
      "4  850632420365873152        MH17files   \n",
      "\n",
      "                                                text  \\\n",
      "0  RT @_Gafas_y_reloj_: El nulo inter√©s de PP y C...   \n",
      "1  RT @MTudela: ‚ÄòT√© gr√†cia estudiar a una univers...   \n",
      "2  Las empresas valencianas pueden solicitar #sub...   \n",
      "3  #espa√±aesuna #stopUE #stopOTAN #stopLGTB #stop...   \n",
      "4  RT @pthefigg: @EliotHiggins @benimmo @DFRLab @...   \n",
      "\n",
      "                                            hashtags  contains_ref_hashtag  \\\n",
      "0                                                                        0   \n",
      "1                                                                        0   \n",
      "2         subvenciones,contratacion,jovenes,Valencia                     0   \n",
      "3  espa√±aesuna,stopUE,stopOTAN,stopLGTB,stopgloba...                     0   \n",
      "4                                        bellingcrap                     0   \n",
      "\n",
      "  lang  lang_conf  retweeted  \n",
      "0   es   1.000000          1  \n",
      "1   ca   1.000000          1  \n",
      "2   es   1.000000          0  \n",
      "3   es   1.000000          0  \n",
      "4   sw   0.428915          1  \n"
     ]
    }
   ],
   "source": [
    "all_tweet_data = pd.read_csv('../../data/tweets/extra_user_tweets/Jan-01-17_Oct-31-17_user_tweets.tsv', sep='\\t', index_col=False)\n",
    "# fillna\n",
    "all_tweet_data.fillna('', inplace=True)\n",
    "print(all_tweet_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tag at-replies\n",
    "import re\n",
    "at_matcher = re.compile('@\\w+')\n",
    "all_tweet_data.loc[:, 'reply'] = all_tweet_data.apply(lambda r: int(len(at_matcher.findall(r.loc['text'])) > 0 and r.loc['retweeted']==0), axis=1)\n",
    "# and hashtag counts\n",
    "all_tweet_data.loc[:, 'hashtag_count'] = all_tweet_data.loc[:, 'hashtags'].apply(lambda x: len(x.split(',')) if x != '' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for difference in reply vs. non-reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.812205\n",
      "1    0.187795\n",
      "Name: reply, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(all_tweet_data.loc[:, 'reply'].value_counts() / all_tweet_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 18% of tweets are replies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter for retweets\n",
    "tweet_data_original = all_tweet_data[all_tweet_data.loc[:, 'retweeted'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.510152\n",
      "1    0.489848\n",
      "Name: reply, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# count replies\n",
    "print(tweet_data_original.loc[:, 'reply'].value_counts() / tweet_data_original.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better ratio!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis:\n",
    "\n",
    "$H_{0}$: Tweeters who use @-replies are just as likely to use Catalan in @-reply as in non-reply (controlling for hashtag usage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1267\n",
      "1     386\n",
      "Name: reply, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tweet_data_original_with_ref = tweet_data_original[tweet_data_original.loc[:, 'contains_ref_hashtag']==1]\n",
    "print(tweet_data_original_with_ref.loc[:, 'reply'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small sample size...but we push ahead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 relevant users\n",
      "128 relevant tweets\n"
     ]
    }
   ],
   "source": [
    "relevant_users = tweet_data_original_with_ref.groupby('user').apply(lambda x: (x.loc[:, 'reply'].min()==0 and\n",
    "                                                                               x.loc[:, 'reply'].max()==1))\n",
    "relevant_users = relevant_users[relevant_users].index.tolist()\n",
    "print('%d relevant users'%(len(relevant_users)))\n",
    "tweet_data_original_with_ref_relevant = tweet_data_original_with_ref[tweet_data_original_with_ref.loc[:, 'user'].isin(relevant_users)]\n",
    "print('%d relevant tweets'%(tweet_data_original_with_ref_relevant.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_u = 0.17974, err = 0.42275, t=3.036 (p=3.798E-03)\n"
     ]
    }
   ],
   "source": [
    "# compute differences in CA use\n",
    "from __future__ import division\n",
    "from scipy.stats import ttest_1samp\n",
    "tweet_data_original_with_ref_relevant_reply = tweet_data_original_with_ref_relevant[tweet_data_original_with_ref_relevant.loc[:, 'reply']==1]\n",
    "tweet_data_original_with_ref_relevant_non_reply = tweet_data_original_with_ref_relevant[tweet_data_original_with_ref_relevant.loc[:, 'reply']==0]\n",
    "ca_reply_use = tweet_data_original_with_ref_relevant_reply.groupby('user').apply(lambda x: (x.loc[:, 'lang']=='ca').astype(int).sum() / x.shape[0])\n",
    "ca_non_reply_use = tweet_data_original_with_ref_relevant_non_reply.groupby('user').apply(lambda x: (x.loc[:, 'lang']=='ca').astype(int).sum() / x.shape[0])\n",
    "ca_use_diff = ca_reply_use - ca_non_reply_use\n",
    "d_u = ca_use_diff.mean()\n",
    "d_u_err = ca_use_diff.std()\n",
    "h_0 = 0.\n",
    "t_stat, p_val = ttest_1samp(ca_use_diff, h_0)\n",
    "print('d_u = %.5f, err = %.5f, t=%.3f (p=%.3E)'%(d_u, d_u_err, t_stat, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion 1**:\n",
    "\n",
    "When only considering tweets with a referendum hashtag, slightly more use of Catalan in replies ($d_{u}=0.157, p=0.00380$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weaker condition: use all tweets that contain at least one hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24057 tweets with at least one hashtag\n"
     ]
    }
   ],
   "source": [
    "tweet_data_original_with_hashtag = tweet_data_original[tweet_data_original.loc[:, 'hashtag_count'] > 0]\n",
    "print('%d tweets with at least one hashtag'%(tweet_data_original_with_hashtag.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def run_test(tweet_data):\n",
    "    relevant_users = tweet_data.groupby('user').apply(lambda x: (x.loc[:, 'reply'].min()==0 and\n",
    "                                                                 x.loc[:, 'reply'].max()==1))\n",
    "    relevant_users = relevant_users[relevant_users].index.tolist()\n",
    "    tweet_data_relevant = tweet_data[tweet_data.loc[:, 'user'].isin(relevant_users)]\n",
    "    print('%d relevant users'%(len(relevant_users)))\n",
    "    print('%d relevant tweets'%(tweet_data.shape[0]))\n",
    "    tweet_data_relevant_reply = tweet_data_relevant[tweet_data_relevant.loc[:, 'reply']==1]\n",
    "    tweet_data_relevant_non_reply = tweet_data_relevant[tweet_data_relevant.loc[:, 'reply']==0]\n",
    "    ca_reply_use = tweet_data_relevant_reply.groupby('user').apply(lambda x: (x.loc[:, 'lang']=='ca').astype(int).sum() / x.shape[0])\n",
    "    ca_non_reply_use = tweet_data_relevant_non_reply.groupby('user').apply(lambda x: (x.loc[:, 'lang']=='ca').astype(int).sum() / x.shape[0])\n",
    "    ca_use_diff = ca_reply_use - ca_non_reply_use\n",
    "    d_u = ca_use_diff.mean()\n",
    "    N = len(ca_use_diff)\n",
    "    d_u_err = ca_use_diff.std() / N**.5\n",
    "    h_0 = 0.\n",
    "    t_stat, p_val = ttest_1samp(ca_use_diff, h_0)\n",
    "    print('d_u = %.5f, err = %.5f, t=%.3f (p=%.3E)'%(d_u, d_u_err, t_stat, p_val))\n",
    "    return d_u, d_u_err, t_stat, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476 relevant users\n",
      "24057 relevant tweets\n",
      "d_u = -0.00784, err = 0.01426, t=-0.550 (p=5.825E-01)\n"
     ]
    }
   ],
   "source": [
    "test_results = run_test(tweet_data_original_with_hashtag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion 2**:\n",
    "\n",
    "Insignificant tendency toward less Catalan in replies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last test: consider only tweets that have no hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57401 tweets with no hashtags\n"
     ]
    }
   ],
   "source": [
    "tweet_data_original_no_hashtag = tweet_data_original[tweet_data_original.loc[:, 'hashtag_count'] == 0]\n",
    "print('%d tweets with no hashtags'%(tweet_data_original_no_hashtag.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945 relevant users\n",
      "57401 relevant tweets\n",
      "d_u = -0.01135, err = 0.00890, t=-1.275 (p=2.026E-01)\n"
     ]
    }
   ],
   "source": [
    "test_results = run_test(tweet_data_original_no_hashtag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion 3**:\n",
    "\n",
    "Insignificant tendency toward less Catalan in replies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most basic test: @-reply, no hashtag versus no @-reply, hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "def run_compare_test(tweet_data_1, tweet_data_2):\n",
    "    relevant_users = set(tweet_data_1.loc[:, 'user'].unique()) & set(tweet_data_2.loc[:, 'user'].unique())\n",
    "    tweet_data_relevant_1 = tweet_data_1[tweet_data_1.loc[:, 'user'].isin(relevant_users)]\n",
    "    tweet_data_relevant_2 = tweet_data_2[tweet_data_2.loc[:, 'user'].isin(relevant_users)]\n",
    "    print('%d tweets in data 1'%(tweet_data_relevant_1.shape[0]))\n",
    "    print('%d tweets in data 2'%(tweet_data_relevant_2.shape[0]))\n",
    "    print('%d relevant users'%(len(relevant_users)))\n",
    "    ca_1 = tweet_data_relevant_1.groupby('user').apply(lambda x: (x.loc[:, 'lang']=='ca').astype(int).sum() / x.shape[0])\n",
    "    ca_2 = tweet_data_relevant_2.groupby('user').apply(lambda x: (x.loc[:, 'lang']=='ca').astype(int).sum() / x.shape[0])\n",
    "    ca_use_diff = ca_1 - ca_2\n",
    "    d_u = ca_use_diff.mean()\n",
    "    N = len(ca_use_diff)\n",
    "    d_u_err = ca_use_diff.std() / N**.5\n",
    "    h_0 = 0.\n",
    "    t_stat, p_val = ttest_1samp(ca_use_diff, h_0)\n",
    "    print('d_u = %.5f, err = %.5f, t=%.3f (p=%.3E)'%(d_u, d_u_err, t_stat, p_val))\n",
    "    return d_u, d_u_err, t_stat, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_data_1 = tweet_data_original[(tweet_data_original.loc[:, 'reply']==1) & (tweet_data_original.loc[:, 'hashtag_count']==0)]\n",
    "tweet_data_2 = tweet_data_original[(tweet_data_original.loc[:, 'reply']==0) & (tweet_data_original.loc[:, 'hashtag_count']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10370 tweets in data 1\n",
      "13650 tweets in data 2\n",
      "921 relevant users\n",
      "d_u = -0.06189, err = 0.01061, t=-5.830 (p=7.647E-09)\n"
     ]
    }
   ],
   "source": [
    "test_results = run_compare_test(tweet_data_1, tweet_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion 4**:\n",
    "\n",
    "Weakly significant effect! **Less** Catalan use in replies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain experiment 2: explore non-referendum topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control hashtags\n",
    "\n",
    "What are the most popular control-data hashtags when we take out the referendum-specific hashtags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_hashtags = pd.read_csv('../../data/expanded_fixed_hashtags.csv', index_col=False).loc[:, 'expanded'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starmetre                  1324\n",
      "Venezuela                   806\n",
      "Barcelona                   743\n",
      "Espa√±a                      581\n",
      "buscandoapacomolina         578\n",
      "Catalunya                   459\n",
      "StarMetre:                  440\n",
      "WorldWide                   440\n",
      "Trends                      439\n",
      "stopLGTB                    403\n",
      "espa√±aesuna                 394\n",
      "LoM√°sVisto                  375\n",
      "√öltimaHora                  368\n",
      "Resistencia                 358\n",
      "URGENTE                     352\n",
      "beBee                       348\n",
      "LoM√°sLe√≠do                  346\n",
      "‚Ä¶                           333\n",
      "Caracas                     331\n",
      "PP                          320\n",
      "SOSVenezuela                309\n",
      "ResistenciaVzla             302\n",
      "LaTorturaNoEsCultura        301\n",
      "HijoPutismo                 298\n",
      "AHORA                       297\n",
      "StarMetre                   292\n",
      "Noticias                    291\n",
      "profesReligi√≥n              280\n",
      "stopUE                      273\n",
      "NoTeLoPierdas               273\n",
      "PSOE                        257\n",
      "EstafaBancoPopular          239\n",
      "Pol√≠tica                    237\n",
      "VenezuelaLibre              234\n",
      "Rajoy                       229\n",
      "RecuperemElSeny             217\n",
      "Valencia                    214\n",
      "Parlament                   212\n",
      "Catalonia                   209\n",
      "profesReligion              205\n",
      "FelizDomingo                198\n",
      "AutoDefensas                185\n",
      "TuitUtil                    179\n",
      "LlibertatJordis             176\n",
      "Insurgencia                 174\n",
      "Defiendete                  173\n",
      "Contraataque                170\n",
      "stopglobalizacion           167\n",
      "DefensaPropia               166\n",
      "Rebeld√≠a                    165\n",
      "Disidencia                  165\n",
      "MLB                         160\n",
      "SomosSocialistas            158\n",
      "1O?                         157\n",
      "MarcaEspa√±a                 157\n",
      "Catalu√±a                    157\n",
      "DerechoDeRebeli√≥n           154\n",
      "Madrid                      152\n",
      "Leg√≠timaDefensa             150\n",
      "Democracia                  149\n",
      "DerechoDeResistencia        149\n",
      "Cs                          148\n",
      "LaInminencia                145\n",
      "FelizLunes                  143\n",
      "Partisano                   142\n",
      "LaOfensiva                  140\n",
      "DerechoDeRevoluci√≥n         137\n",
      "NoTincPor                   136\n",
      "FelizMartes                 134\n",
      "FelizJueves                 134\n",
      "10Oct                       133\n",
      "GuardiaCivil                131\n",
      "BelenEsteban                131\n",
      "DuiARV                      128\n",
      "PSC                         125\n",
      "√öLTIMAHORA                  121\n",
      "2Oct                        120\n",
      "1oEstafaAntidemocratica     117\n",
      "1OCT                        117\n",
      "ArdeGalicia                 117\n",
      "EspanaSaleALaCalle          116\n",
      "FelizSabado                 112\n",
      "ACTUALIDAD                  111\n",
      "sosprisiones                110\n",
      "FakeNews                    109\n",
      "EquiparacionYa              108\n",
      "12octFiestaNacional         107\n",
      "DUI                         107\n",
      "CLM                         106\n",
      "stopislam                   106\n",
      "3Oct                        105\n",
      "pactoEducaci√≥n              105\n",
      "Podemos                     104\n",
      "MiVoto40KatyPerry           103\n",
      "RT                          103\n",
      "MarcaEspa√±a:                 96\n",
      "CatalanReferendum‚Ä¶           90\n",
      "UP                           88\n",
      "stopsionismo                 86\n",
      "vipdirecto                   86\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "pd.set_option('display.max_rows', 100)\n",
    "hashtag_counts = [l.strip().split(' ') for l in codecs.open('../../data/tweets/extra_user_tweets/hashtags_counts.txt')]\n",
    "hashtag_counts = filter(lambda x: len(x)>1, hashtag_counts)\n",
    "hashtag_counts = pd.Series(dict([(h[1], int(h[0])) for h in hashtag_counts])).sort_values(inplace=False, ascending=False)\n",
    "# remove ref hashtags\n",
    "ref_hashtags_intersect = set(ref_hashtags) & set(hashtag_counts.index)\n",
    "hashtag_counts.drop(ref_hashtags_intersect, axis=0, inplace=True)\n",
    "print(hashtag_counts.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why so many Venezuela tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "all data\n",
      "--------------\n",
      "\n",
      "Hablamos con el economista, Jos√© Manuel Puente, para analizar la situaci√≥n de #Venezuela https://t.co/L0ElvfF4dC\n",
      "No van a tener nada para saquear si seguimos desabasteciendo las tiendas. #Venezuela https://t.co/v8OEwgkzO5\n",
      "Pray for Venezuela üÜòüáªüá™üÜò Reza por Venezuela üÜòüáªüá™ üÜò #SOSvenezuela #Venezuela #PrayForVenezuela @Pontifex_es üáªüá™‚Ä¶ https://t.co/ZHQQUZCm4y\n",
      "@SextaNocheTV Que verg√ºenza de entrevista @Pablo_Iglesias_ emergencia nacional es la que esta sufriendo #VenezuelaEnDictadura\n",
      "Periodistas agredidos y robados durante la marcha opositora en Caracas https://t.co/KgAJhWXFTX v√≠a @EFEnoticias #derechagolpista #Venezuela\n",
      "teleSURtv: #Venezuela: 'Amenaza de EE.UU. contra el pa√≠s es un acto de locura' https://t.co/yrqGLIS7WH https://t.co/gL3oyFZwnB teleSURtv\n",
      "¬øC√≥mo se puede definir un Estado? https://t.co/53Fv3X7WYT 601I AA OS #Venezuela\n",
      "Cuando el chiste se cuenta SOLITO: #TrumpNoPodrasConVenezuela https://t.co/onD35iPTfj HZ #Venezuela UD #Leg√≠timaDefensa\n",
      "#Alerta ¬°FAVOR RT! 4 d√≠as de la desaparici√≥n forzada de mi pap√° @RaulBaduel EXIGIMOS FE DE VIDA.‚Ä¶ https://t.co/bFtNJTHgcR TX #Venezuela\n",
      "Trump: no al comercio desleal y a pagar el 70% de la OTAN. https://t.co/1e6xBNZdgh 119R PH #LoM√°sVisto WR #Venezuela\n",
      "La Abstenci√≥n https://t.co/tZ2rTWk5UX 66T PH #LoM√°sVisto PV #Noticias KR #Venezuela\n",
      "teleSURtv: #EnVivo | Pdta del #CNE de #Venezuela, Tibisay Lucena, ofrece detalles del cronograma de elecciones regionales‚Ä¶ ‚Ä¶\n",
      "Segundo intento: https://t.co/vkPGF2ro1P https://t.co/La22YyVdh2 YG #LaOfensiva AV #SOSVenezuela\n",
      "teleSURtv: #VenezuelaConstituyente prepara medidas de defensa ante amenaza de EE.UU. https://t.co/9ga5KKzop3 https://t.co/Z0kjbaotUw tele‚Ä¶\n",
      "@Mochima Sjajjajajajasj XC #SOSVenezuela XL #EstadoDeNecesidad\n",
      "@ibepacheco @angelDPG El se la da de Mongolico pero es tremendo Narcotraficante y Asesino como el padre XA #Contraataque HM #Venezuela\n",
      "El √∫nico parlamentarismo es el brit√°nico https://t.co/1DQlnhsumQ 110T CM #Noticias BX #URGENTE QV #Venezuela\n",
      "Esto terminar√° muy mal para los dialogantes y proponentes electoreros https://t.co/p7nGPGkves 144| #DefensaPropia AO #SOSVenezuela\n",
      "Faltan otras definiciones militares. 30/6/17 Alberto Franceschi https://t.co/unp6SipQiu 7&lt; # EstadoDeNecesidad PI #SOSVenezuela\n",
      "Para los que piensan que la salida DEL PEO es VOTANDO POR LA PARTIDOCRACIA https://t.co/Blr5MhZZCo 215* #Leg√≠timaDefensa ZE #SOSVenezuela\n",
      "¬øQu√© les dir√≠a a los votantes de PODEMOS? https://t.co/HAn97uwhUd 409E VL #Venezuela\n",
      "Es parte de tu Libertad, VIVA LA GUARIMBA LIBERTARIA https://t.co/NOUXpQw6i8. 21x QJ #SOSVenezuela\n",
      "Militares De Ustedes Dependemos para Sacar la Dictadura, Franceschi 3/8/17 https://t.co/CPKlDCB3gU 28x #Defiendete KA #SOSVenezuela\n",
      "Mas de 1 mill√≥n de Euros le pagaron al enchufado de monedero por asesorar a Ch√°vez https://t.co/H5S9p4xuN6 CI #SOSVenezuela\n",
      "La diferencia la marca la LIBERTAD POL√çTICA COLECTIVA. Franco VS Lincoln. https://t.co/CA1pdBWb8a 340B AL #Venezuela\n",
      "Delenda est Venezuela https://t.co/1HMx0ct0W3 430A YE #VenezuelaLibre\n",
      "For most of the 20th and 21st centuries, people from #Colombia moved to #Venezuela to improve their fortunes. Not ‚Ä¶ https://t.co/Q7b1HQepjq\n",
      "Libertad de pensamiento https://t.co/5urPs0kS2x 405x VC #Venezuela\n",
      "Yo Soy Un ESCUDERO, Yo Soy LIBERTADOR https://t.co/Z5NeR0JMff 131 #Insurgencia R FU #SOSVenezuela\n",
      "Entrevista a D Antonio Garc√≠a Trevijano ?????? ??????? ?????? ????????? https://t.co/5XFXR5DDub 294A OU #Noticias RE #Venezuela\n",
      "¬øSe deben incluir derechos sociales en una Constituci√≥n? Revoluci√≥n Francesa la Bastilla https://t.co/lLfxqjL27U 483x SS #SOSVenezuela\n",
      "¬øC√≥mo es posible que Espa√±a tenga tanta deuda? https://t.co/9Tfuumk90C 570Q SY #SOSVenezuela\n",
      "La \"izquierda\" niega a Marx y a Lenin cuando hablan de la autodeterminaci√≥n. https://t.co/bBDpK5DbwO 644H NT #SOSVenezuela\n",
      "GNB PNB Y Fanb VuelvanCaras por cada preso indefenso, son 10 de verdes q caer√°n, https://t.co/dnc48e5wVz #AutoDefensas 76. GF #Venezuela\n",
      "El sujeto constituyente https://t.co/YEYcp0BGOd 52¬∫ OB #NoTeLoPierdas ES #SOSVenezuela\n",
      "RLC ( 2017-07-05 ) Naciones culturales, raza y lengua. https://t.co/zstgHKxE0b 207X BJ #VenezuelaLibre\n",
      "Despu√©s de los partidos estatales ¬øqu√©? AG Trevijano https://t.co/9W8Xc5UgTu 114, GC #Venezuela\n",
      "La Representaci√≥n Moral vs. Material. Arrow, Condorcet y Stuart Mill https://t.co/Bl6MJCkpJ2 447F PN #Venezuela\n",
      "teleSURtv: #Rusia rechaza amenazas de intervenci√≥n contra #Venezuela https://t.co/m1td7TFqUb https://t.co/52JzzNslbj teleSURtv\n",
      "teleSURtv: #Venezuela rechaza injerencias de canciller √Ångela Merkel https://t.co/Co7vMJ2ocW https://t.co/cooeKdf6KT teleSURtv\n",
      "@ErikaOSanoja @Maby80 @manelmarquez si gob d (USA) apoya a escuderos en #Venezuela y lideres q fomentan odio;cu√°l es su discurso sobre esto?\n",
      "PODEMOS y el SISTEMA ELECTORAL MIXTO ALEM√ÅN https://t.co/GJus4IdLIK 707T QA #SOSVenezuela\n",
      "Garc√≠a Trevijano habla de RUSIA y su relaci√≥n con Espa√±a ??????? ???????... https://t.co/uYEnU7l0kc 107q ZQ #URGENTE VS #VenezuelaLibre\n",
      "Alberto Franceschi: Desalojar YA la dictadura de Maduro-Castro-PSUV por acci√≥n de las FFAA https://t.co/6SXJxMDfrK 155Q TE #Venezuela\n",
      "Mensaje de Alberto Franceschi https://t.co/qdRFq7w6Pn 38H AE #LoM√°sVisto UM #SOSVenezuela OT #NoTeLoPierdas\n",
      "La Libertad Constituyente Heliodoro Rodr√≠guez en Ya Es Domigo https://t.co/fosFrKfEjk 34Z DU #URGENTE CK #LoM√°sVisto PG #VenezuelaLibre\n",
      "teleSURtv: Canciller√≠a de #Rusia afirma que intervenir #Venezuela es atacar a Am√©rica Latina https://t.co/Cl5BFspwiN ‚Ä¶\n",
      "Es la hora de la libertad pol√≠tica https://t.co/v1haQElSK4 72Z ZJ #NoTeLoPierdas IR #SOSVenezuela OL #LoM√°sVisto\n",
      "Los indignados del 15M. https://t.co/MngpS8I6IY 114U VK #Venezuela OQ #Noticias\n",
      "La ventaja de la doble vuelta en Francia vs. Sistema simple y proporcional https://t.co/OV9l3oAdCd 457F YE #Venezuela\n",
      "--------------\n",
      "contains referendum hashtag\n",
      "--------------\n",
      "\n",
      "@AntonioMaestre Acto seguido organiz√°is otra manifa por vuestra gente de #Venezuela #TotsSomCatalunya\n",
      "No sirven para nada. Fuera todos. #ProuPuigdemont https://t.co/4OCD395NhR BH #SOSVenezuela PW #Leg√≠timaDefensa\n",
      "#ProuPuigdemont . No votes. Abstenci√≥n ACtiva. https://t.co/aLcj82YdD9 KF #Venezuela BU #Resistencia\n",
      "#ProuPuigdemont https://t.co/zfKOXP4cYY ZR #VenezuelaLibre\n",
      "Animo! Pueblo Catalan y Venezolano el mundo est√° con ustedes #CatalunaLibre #Venezuela\n"
     ]
    }
   ],
   "source": [
    "test_hashtag = 'Venezuela'\n",
    "tweet_data_with_hashtag = tweet_data_original[tweet_data_original.loc[:, 'hashtags'].apply(lambda x: test_hashtag in x)]\n",
    "print('--------------\\nall data\\n--------------\\n')\n",
    "print('\\n'.join(tweet_data_with_hashtag.loc[:, 'text'].head(50).values.tolist()))\n",
    "print('--------------\\ncontains referendum hashtag\\n--------------\\n')\n",
    "print('\\n'.join(tweet_data_with_hashtag[tweet_data_with_hashtag.loc[:, 'contains_ref_hashtag']==1].loc[:, 'text'].head(50).values.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this driven by a small group of users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola8400           150\n",
      "jhenderm6          123\n",
      "CanariasMcrc        68\n",
      "mcrc_valladolid     61\n",
      "McrcJaen            60\n",
      "MCRC_Vizcaya        55\n",
      "McrcMurcia          54\n",
      "McrcGuipuzcoa       53\n",
      "mcrc_bcn            51\n",
      "GranadaRC           50\n",
      "Coruna_MCRC         47\n",
      "JapreriaVZ          47\n",
      "BariVenezuela       46\n",
      "betxi_castellon     37\n",
      "IndioMapoyo         29\n",
      "LaRioja_DRC         29\n",
      "grubell_d3v          3\n",
      "mywordsworlds1       3\n",
      "Bank_Practices       2\n",
      "homequevai           2\n",
      "manelmarquez         2\n",
      "ivonnediaz2203       2\n",
      "social_article       2\n",
      "allsetic             2\n",
      "PostreDulce          2\n",
      "adrifadi             1\n",
      "Britovius            1\n",
      "danicorderom         1\n",
      "ThamarManrique       1\n",
      "mostrenco2           1\n",
      "pirataneko           1\n",
      "Municipal_Bank       1\n",
      "mcrc_almeria         1\n",
      "jeff_puente          1\n",
      "PartidoPodrido       1\n",
      "PuesPioPio           1\n",
      "kattolikamente       1\n",
      "libro_lector         1\n",
      "StarMetre            1\n",
      "DonKshu              1\n",
      "IsaTorres78          1\n",
      "socialistahn         1\n",
      "laura_castro3        1\n",
      "SoyCibelino          1\n",
      "Agusti_RM            1\n",
      "manuel_becerrea      1\n",
      "elhilorojo           1\n",
      "jaguimera            1\n",
      "JordiJobatcar        1\n",
      "Lamiabrunetta        1\n",
      "Ataloya              1\n",
      "NavarroMescua        1\n",
      "LlopisMarta95        1\n",
      "OrenseMCRC           1\n",
      "TheObjective_es      1\n",
      "eyeclipse            1\n",
      "bechoch              1\n",
      "bettinagalo          1\n",
      "14manu2013           1\n",
      "JUnodmadrid          1\n",
      "DorisRiveroL         1\n",
      "Marisabeluchi        1\n",
      "IvanGarciaMayer      1\n",
      "RayMcCoyBR           1\n",
      "Name: user, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweet_data_with_hashtag.loc[:, 'user'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
